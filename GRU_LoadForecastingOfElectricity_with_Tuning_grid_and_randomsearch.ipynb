{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Imports and setup"
      ],
      "metadata": {
        "id": "oAB8sG_WtgoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycKgGH0WtXF1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "hY6WdAPvt7Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/electricitydemanddata.csv')\n",
        "print(df.columns.tolist())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sFHvc6xt_Y5",
        "outputId": "fc940725-2cd1-44a8-b284-4be470c0d894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date', 'Day of the week', 'Year', 'Month', 'Max. Demand at eve. peak (Generation end)', 'Max. Demand at eve. peak (Sub-station end)', 'Highest Generation (Generation end)', 'Minimum Generation (Generation end)', 'Day-peak Generation (Generation end)', 'Evening-peak Generation (Generation end)', 'Minimum Generation Forecast up to 8:00 hrs.', 'Maximum Temperature in Dhaka was', 'Gas/LF limitation', 'Coal supply Limitation', 'Low water level in Kaptai lake', 'Plants under shut down/ maintenance', 'Dhaka_demand', 'Dhaka_supply', 'Dhaka_load', 'Chattogram_demand', 'Chattogram_supply', 'Chattogram_load', 'Rajshahi_demand', 'Rajshahi_supply', 'Rajshahi_load', 'Mymensingh_demand', 'Mymensingh_supply', 'Mymensingh_load', 'Sylhet_demand', 'Sylhet_supply', 'Sylhet_load', 'Barishal_demand', 'Barishal_supply', 'Barishal_load', 'Rangpur_demand', 'Rangpur_supply', 'Rangpur_load', 'Cumilla_demand', 'Cumilla_supply', 'Cumilla_load', 'Khulna_demand', 'Khulna_supply', 'Khulna_load', 'Holiday name', 'Holiday_cat']\n",
            "                  Date Day of the week  Year  Month  \\\n",
            "0  2019-11-21 00:00:00        Thursday  2019     11   \n",
            "1  2019-11-22 00:00:00          Friday  2019     11   \n",
            "2  2019-11-23 00:00:00        Saturday  2019     11   \n",
            "3  2019-11-24 00:00:00          Sunday  2019     11   \n",
            "4  2019-11-25 00:00:00          Monday  2019     11   \n",
            "\n",
            "   Max. Demand at eve. peak (Generation end)  \\\n",
            "0                                       8785   \n",
            "1                                       7886   \n",
            "2                                       8827   \n",
            "3                                       8855   \n",
            "4                                       8982   \n",
            "\n",
            "   Max. Demand at eve. peak (Sub-station end)  \\\n",
            "0                                      8110.0   \n",
            "1                                      7344.0   \n",
            "2                                      8197.0   \n",
            "3                                      8224.0   \n",
            "4                                      8356.0   \n",
            "\n",
            "   Highest Generation (Generation end)  Minimum Generation (Generation end)  \\\n",
            "0                               8785.0                               5647.0   \n",
            "1                               7886.0                               5283.5   \n",
            "2                               8827.0                               5200.0   \n",
            "3                               8855.0                               5470.0   \n",
            "4                               8978.0                               5500.0   \n",
            "\n",
            "   Day-peak Generation (Generation end)  \\\n",
            "0                                7294.7   \n",
            "1                                5725.9   \n",
            "2                                6731.7   \n",
            "3                                7062.8   \n",
            "4                                7110.7   \n",
            "\n",
            "   Evening-peak Generation (Generation end)  ...  Rangpur_supply  \\\n",
            "0                                      8785  ...             208   \n",
            "1                                      7886  ...             201   \n",
            "2                                      8946  ...             210   \n",
            "3                                      8855  ...             216   \n",
            "4                                      8982  ...             219   \n",
            "\n",
            "   Rangpur_load  Cumilla_demand  Cumilla_supply  Cumilla_load  Khulna_demand  \\\n",
            "0             0             701             701             0            953   \n",
            "1             0             694             694             0            908   \n",
            "2             0             729             729             0            974   \n",
            "3             0             722             722             0            983   \n",
            "4             0             735             735             0            981   \n",
            "\n",
            "   Khulna_supply  Khulna_load  Holiday name  Holiday_cat  \n",
            "0            953            0    No Holiday            0  \n",
            "1            908            0    No Holiday            0  \n",
            "2            974            0    No Holiday            0  \n",
            "3            983            0    No Holiday            0  \n",
            "4            981            0    No Holiday            0  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Preprocessing"
      ],
      "metadata": {
        "id": "wq_iHc57uJtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert boolean columns to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype(float)\n",
        "\n",
        "# Drop non-numeric columns\n",
        "df = df.drop(columns=['Date', 'Holiday name'])\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "df = pd.get_dummies(df, columns=['Day of the week', 'Month', 'Holiday_cat'], drop_first=True)\n",
        "\n",
        "# Identify feature and target columns\n",
        "target_cols = [col for col in df.columns if '_demand' in col]\n",
        "feature_cols = [col for col in df.columns if col not in target_cols]\n",
        "\n",
        "# Features and target arrays\n",
        "X = df[feature_cols].values.astype(np.float32)\n",
        "y = df[target_cols].values.astype(np.float32)\n",
        "\n",
        "# Scale separately\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X = feature_scaler.fit_transform(X)\n",
        "y = target_scaler.fit_transform(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "KDoMpfCUxCD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4️⃣ Create multi-step GRU dataset\n"
      ],
      "metadata": {
        "id": "yo94pTZ9xIhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gru_dataset_multioutput(X, y, lookback=21, horizon=2):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(lookback, len(X)-horizon+1):\n",
        "        Xs.append(X[i-lookback:i])\n",
        "        ys.append(y[i:i+horizon])\n",
        "    return np.array(Xs, dtype=np.float32), np.array(ys, dtype=np.float32)\n",
        "\n",
        "lookback = 21  # input window\n",
        "horizon = 2    # 48-hour forecast (2 days)\n",
        "\n",
        "X_gru, y_gru = create_gru_dataset_multioutput(X, y, lookback, horizon)\n",
        "print(\"X shape:\", X_gru.shape)\n",
        "print(\"y shape:\", y_gru.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpn1DH616Qx2",
        "outputId": "6b253fa0-b706-4db0-f3c9-1142bd5da9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1828, 21, 51)\n",
            "y shape: (1828, 2, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5️⃣ Train / Validation / Test split"
      ],
      "metadata": {
        "id": "EJDUuYjZ6qsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = len(X_gru)\n",
        "train_end = int(total_samples * 0.7)\n",
        "val_end = int(total_samples * 0.85)\n",
        "\n",
        "X_train, y_train = X_gru[:train_end], y_gru[:train_end]\n",
        "X_val, y_val = X_gru[train_end:val_end], y_gru[train_end:val_end]\n",
        "X_test, y_test = X_gru[val_end:], y_gru[val_end:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Validation:\", X_val.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "num_features = X_train.shape[2]\n",
        "num_targets = y_train.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SxraZUK8NDp",
        "outputId": "9762d226-d1a5-470a-c88c-b19aa20b6f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (1279, 21, 51) Validation: (274, 21, 51) Test: (275, 21, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6️⃣ Build GRU model"
      ],
      "metadata": {
        "id": "2DqebIf78XWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(64, input_shape=(lookback, num_features), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(horizon * num_targets))  # flatten output\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "J3CG7mMM8dRa",
        "outputId": "820bcb19-afc0-42a3-e1f1-ae36293814f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m22,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m594\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,466\u001b[0m (126.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,466</span> (126.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,466\u001b[0m (126.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,466</span> (126.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7️⃣ Train GRU model"
      ],
      "metadata": {
        "id": "kQCt49Me8hly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train.reshape(y_train.shape[0], horizon*num_targets),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DKkW-z98l5M",
        "outputId": "891f84a8-ab2e-4cbf-f92e-968626592915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 - 5s - 127ms/step - loss: 0.0675\n",
            "Epoch 2/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0285\n",
            "Epoch 3/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0225\n",
            "Epoch 4/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0194\n",
            "Epoch 5/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0154\n",
            "Epoch 7/50\n",
            "40/40 - 2s - 40ms/step - loss: 0.0145\n",
            "Epoch 8/50\n",
            "40/40 - 2s - 49ms/step - loss: 0.0144\n",
            "Epoch 9/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0131\n",
            "Epoch 10/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0123\n",
            "Epoch 11/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0114\n",
            "Epoch 12/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0113\n",
            "Epoch 13/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0108\n",
            "Epoch 14/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0103\n",
            "Epoch 15/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0099\n",
            "Epoch 16/50\n",
            "40/40 - 1s - 30ms/step - loss: 0.0096\n",
            "Epoch 17/50\n",
            "40/40 - 2s - 40ms/step - loss: 0.0094\n",
            "Epoch 18/50\n",
            "40/40 - 1s - 32ms/step - loss: 0.0093\n",
            "Epoch 19/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0086\n",
            "Epoch 20/50\n",
            "40/40 - 1s - 33ms/step - loss: 0.0086\n",
            "Epoch 21/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0088\n",
            "Epoch 22/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0083\n",
            "Epoch 23/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0080\n",
            "Epoch 24/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0082\n",
            "Epoch 25/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0076\n",
            "Epoch 26/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0078\n",
            "Epoch 27/50\n",
            "40/40 - 2s - 45ms/step - loss: 0.0076\n",
            "Epoch 28/50\n",
            "40/40 - 2s - 41ms/step - loss: 0.0074\n",
            "Epoch 29/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0074\n",
            "Epoch 30/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0073\n",
            "Epoch 31/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0071\n",
            "Epoch 32/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0070\n",
            "Epoch 33/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0069\n",
            "Epoch 34/50\n",
            "40/40 - 1s - 24ms/step - loss: 0.0068\n",
            "Epoch 35/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0067\n",
            "Epoch 36/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0066\n",
            "Epoch 37/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0065\n",
            "Epoch 38/50\n",
            "40/40 - 2s - 41ms/step - loss: 0.0065\n",
            "Epoch 39/50\n",
            "40/40 - 2s - 41ms/step - loss: 0.0064\n",
            "Epoch 40/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0062\n",
            "Epoch 41/50\n",
            "40/40 - 1s - 27ms/step - loss: 0.0064\n",
            "Epoch 42/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0062\n",
            "Epoch 43/50\n",
            "40/40 - 1s - 25ms/step - loss: 0.0063\n",
            "Epoch 44/50\n",
            "40/40 - 1s - 33ms/step - loss: 0.0061\n",
            "Epoch 45/50\n",
            "40/40 - 1s - 26ms/step - loss: 0.0061\n",
            "Epoch 46/50\n",
            "40/40 - 1s - 26ms/step - loss: 0.0059\n",
            "Epoch 47/50\n",
            "40/40 - 1s - 31ms/step - loss: 0.0061\n",
            "Epoch 48/50\n",
            "40/40 - 1s - 26ms/step - loss: 0.0059\n",
            "Epoch 49/50\n",
            "40/40 - 2s - 41ms/step - loss: 0.0060\n",
            "Epoch 50/50\n",
            "40/40 - 2s - 53ms/step - loss: 0.0060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8️⃣ Evaluate on Train Set"
      ],
      "metadata": {
        "id": "P7jATOnF-BuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model.predict(X_train).reshape(y_train.shape[0], horizon, num_targets)\n",
        "y_train_inv = target_scaler.inverse_transform(y_train.reshape(-1, num_targets)).reshape(y_train.shape)\n",
        "y_train_pred_inv = target_scaler.inverse_transform(y_train_pred.reshape(-1, num_targets)).reshape(y_train_pred.shape)\n",
        "\n",
        "mae_train = mean_absolute_error(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets))\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets)))\n",
        "mape_train = np.mean(np.abs((y_train_inv - y_train_pred_inv)/y_train_inv)) * 100\n",
        "r2_train = r2_score(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets))\n",
        "\n",
        "print(\"Train Metrics:\")\n",
        "print(f\"MAE: {mae_train:.2f}, RMSE: {rmse_train:.2f}, MAPE: {mape_train:.2f}%, R²: {r2_train:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw5ihmGW-NlD",
        "outputId": "2d5bf189-8c73-4192-b663-59f34c0b5102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Train Metrics:\n",
            "MAE: 60.71, RMSE: 101.74, MAPE: 5.33%, R²: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9️⃣ Evaluate on Validation Set"
      ],
      "metadata": {
        "id": "-pS1guRA-WsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = model.predict(X_val).reshape(y_val.shape[0], horizon, num_targets)\n",
        "y_val_inv = target_scaler.inverse_transform(y_val.reshape(-1, num_targets)).reshape(y_val.shape)\n",
        "y_val_pred_inv = target_scaler.inverse_transform(y_val_pred.reshape(-1, num_targets)).reshape(y_val_pred.shape)\n",
        "\n",
        "mae_val = mean_absolute_error(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets))\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets)))\n",
        "mape_val = np.mean(np.abs((y_val_inv - y_val_pred_inv)/y_val_inv)) * 100\n",
        "r2_val = r2_score(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets))\n",
        "\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"MAE: {mae_val:.2f}, RMSE: {rmse_val:.2f}, MAPE: {mape_val:.2f}%, R²: {r2_val:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hJOfHkU-aX_",
        "outputId": "9bb8e8e3-b393-43eb-fcd2-66e263decc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Validation Metrics:\n",
            "MAE: 86.73, RMSE: 140.12, MAPE: 7.32%, R²: 0.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10️⃣ Evaluate on Test Set"
      ],
      "metadata": {
        "id": "bS5ONSZp-mEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(X_test).reshape(y_test.shape[0], horizon, num_targets)\n",
        "y_test_inv = target_scaler.inverse_transform(y_test.reshape(-1, num_targets)).reshape(y_test.shape)\n",
        "y_test_pred_inv = target_scaler.inverse_transform(y_test_pred.reshape(-1, num_targets)).reshape(y_test_pred.shape)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test_inv.reshape(-1, num_targets), y_test_pred_inv.reshape(-1, num_targets))\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test_inv.reshape(-1, num_targets), y_test_pred_inv.reshape(-1, num_targets)))\n",
        "mape_test = np.mean(np.abs((y_test_inv - y_test_pred_inv)/y_test_inv)) * 100\n",
        "r2_test = r2_score(y_test_inv.reshape(-1, num_targets), y_test_pred_inv.reshape(-1, num_targets))\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(f\"MAE: {mae_test:.2f}, RMSE: {rmse_test:.2f}, MAPE: {mape_test:.2f}%, R²: {r2_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-LYJ814-sau",
        "outputId": "aba281a4-8022-4f24-ed7d-907146a67ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Test Metrics:\n",
            "MAE: 106.32, RMSE: 168.14, MAPE: 8.35%, R²: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Search using Keras Tuner"
      ],
      "metadata": {
        "id": "6lP66nS9WVhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Keras Tuner"
      ],
      "metadata": {
        "id": "EfU0dEAiX2SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --quiet\n",
        "\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTq8PxdsX4DJ",
        "outputId": "27a06ef0-8cd4-404b-b930-05bd9110a5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build GRU model for tuning"
      ],
      "metadata": {
        "id": "fgdNL4aIX7UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gru_model(hp):\n",
        "    num_features = X_train.shape[2]\n",
        "    num_targets = y_train.shape[2]\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # GRU Layer 1\n",
        "    model.add(GRU(\n",
        "        units=hp.Int('units1', min_value=32, max_value=128, step=32),\n",
        "        input_shape=(lookback, num_features),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout1', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # GRU Layer 2\n",
        "    model.add(GRU(\n",
        "        units=hp.Int('units2', min_value=16, max_value=64, step=16),\n",
        "        return_sequences=False\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout2', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Dense output layer (flatten for multi-step)\n",
        "    model.add(Dense(horizon * num_targets))\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='mse'\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "SVPHH5B7WexZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Random Search tuner"
      ],
      "metadata": {
        "id": "yd8tfj8SYFMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_gru_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # number of hyperparameter combinations to try\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory='gru_tuner',\n",
        "    project_name='regional_demand_gru'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trAmxAKpYLqi",
        "outputId": "c5fa96b3-dea8-4647-8de8-89bb0afa0edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "units1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dropout1 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "units2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "dropout2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the tuner"
      ],
      "metadata": {
        "id": "x60D_9kPYN1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    X_train, y_train.reshape(y_train.shape[0], horizon*num_targets),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val.reshape(y_val.shape[0], horizon*num_targets)),\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WywcP5nMYWTB",
        "outputId": "7117a61c-5996-4cd4-d9ba-5466aa1d1490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 30s]\n",
            "val_loss: 0.01756625436246395\n",
            "\n",
            "Best val_loss So Far: 0.006831677630543709\n",
            "Total elapsed time: 00h 06m 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get best hyperparameters and build model"
      ],
      "metadata": {
        "id": "INiiadREYdk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "print(\"Best Hyperparameters Found:\")\n",
        "print(best_hp.values)\n",
        "\n",
        "# Build the best model using best hyperparameters\n",
        "best_gru_model = tuner.hypermodel.build(best_hp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRa65kYzYeio",
        "outputId": "127437ed-3255-4712-873d-dd9c669b83bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters Found:\n",
            "{'units1': 128, 'dropout1': 0.1, 'units2': 64, 'dropout2': 0.4, 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train best GRU model on training set"
      ],
      "metadata": {
        "id": "CUw3HTEwYijo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = best_gru_model.fit(\n",
        "    X_train,\n",
        "    y_train.reshape(y_train.shape[0], horizon*num_targets),  # flatten multi-step target\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7eNAyeeYmkR",
        "outputId": "33ae2eee-ffb1-4f56-9a58-9545ae0d26b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 - 5s - 135ms/step - loss: 0.0666\n",
            "Epoch 2/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0292\n",
            "Epoch 3/50\n",
            "40/40 - 3s - 77ms/step - loss: 0.0226\n",
            "Epoch 4/50\n",
            "40/40 - 2s - 58ms/step - loss: 0.0191\n",
            "Epoch 5/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0170\n",
            "Epoch 6/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0159\n",
            "Epoch 7/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0145\n",
            "Epoch 8/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0133\n",
            "Epoch 9/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0127\n",
            "Epoch 10/50\n",
            "40/40 - 2s - 41ms/step - loss: 0.0115\n",
            "Epoch 11/50\n",
            "40/40 - 3s - 67ms/step - loss: 0.0112\n",
            "Epoch 12/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0110\n",
            "Epoch 13/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0103\n",
            "Epoch 14/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0101\n",
            "Epoch 15/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0098\n",
            "Epoch 16/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0090\n",
            "Epoch 17/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0090\n",
            "Epoch 18/50\n",
            "40/40 - 4s - 94ms/step - loss: 0.0090\n",
            "Epoch 19/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0088\n",
            "Epoch 20/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0085\n",
            "Epoch 21/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0081\n",
            "Epoch 22/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0081\n",
            "Epoch 23/50\n",
            "40/40 - 1s - 37ms/step - loss: 0.0081\n",
            "Epoch 24/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0083\n",
            "Epoch 25/50\n",
            "40/40 - 2s - 46ms/step - loss: 0.0077\n",
            "Epoch 26/50\n",
            "40/40 - 2s - 60ms/step - loss: 0.0076\n",
            "Epoch 27/50\n",
            "40/40 - 2s - 42ms/step - loss: 0.0075\n",
            "Epoch 28/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0073\n",
            "Epoch 29/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0071\n",
            "Epoch 30/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0072\n",
            "Epoch 31/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0072\n",
            "Epoch 32/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0073\n",
            "Epoch 33/50\n",
            "40/40 - 2s - 62ms/step - loss: 0.0068\n",
            "Epoch 34/50\n",
            "40/40 - 2s - 48ms/step - loss: 0.0069\n",
            "Epoch 35/50\n",
            "40/40 - 2s - 57ms/step - loss: 0.0066\n",
            "Epoch 36/50\n",
            "40/40 - 3s - 63ms/step - loss: 0.0069\n",
            "Epoch 37/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0063\n",
            "Epoch 38/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0064\n",
            "Epoch 39/50\n",
            "40/40 - 2s - 50ms/step - loss: 0.0064\n",
            "Epoch 40/50\n",
            "40/40 - 2s - 62ms/step - loss: 0.0063\n",
            "Epoch 41/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0061\n",
            "Epoch 42/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0062\n",
            "Epoch 43/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0062\n",
            "Epoch 44/50\n",
            "40/40 - 2s - 62ms/step - loss: 0.0059\n",
            "Epoch 45/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0063\n",
            "Epoch 46/50\n",
            "40/40 - 2s - 60ms/step - loss: 0.0062\n",
            "Epoch 47/50\n",
            "40/40 - 2s - 48ms/step - loss: 0.0058\n",
            "Epoch 48/50\n",
            "40/40 - 2s - 39ms/step - loss: 0.0057\n",
            "Epoch 49/50\n",
            "40/40 - 3s - 64ms/step - loss: 0.0057\n",
            "Epoch 50/50\n",
            "40/40 - 2s - 38ms/step - loss: 0.0059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Train"
      ],
      "metadata": {
        "id": "gse9U8nGYpD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_gru_model.predict(X_train).reshape(y_train.shape[0], horizon, num_targets)\n",
        "y_train_inv = target_scaler.inverse_transform(y_train.reshape(-1, num_targets)).reshape(y_train.shape)\n",
        "y_train_pred_inv = target_scaler.inverse_transform(y_train_pred.reshape(-1, num_targets)).reshape(y_train_pred.shape)\n",
        "\n",
        "mae_train = mean_absolute_error(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets))\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets)))\n",
        "mape_train = np.mean(np.abs((y_train_inv - y_train_pred_inv)/y_train_inv)) * 100\n",
        "r2_train = r2_score(y_train_inv.reshape(-1, num_targets), y_train_pred_inv.reshape(-1, num_targets))\n",
        "\n",
        "print(\"Train Metrics:\")\n",
        "print(f\"MAE: {mae_train:.2f}, RMSE: {rmse_train:.2f}, MAPE: {mape_train:.2f}%, R²: {r2_train:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exWT6T1cYtIl",
        "outputId": "022f6704-3362-499e-9339-558ff76b043c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n",
            "Train Metrics:\n",
            "MAE: 57.57, RMSE: 97.59, MAPE: 5.08%, R²: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Validation"
      ],
      "metadata": {
        "id": "a8dkVxouYwDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = best_gru_model.predict(X_val).reshape(y_val.shape[0], horizon, num_targets)\n",
        "y_val_inv = target_scaler.inverse_transform(y_val.reshape(-1, num_targets)).reshape(y_val.shape)\n",
        "y_val_pred_inv = target_scaler.inverse_transform(y_val_pred.reshape(-1, num_targets)).reshape(y_val_pred.shape)\n",
        "\n",
        "mae_val = mean_absolute_error(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets))\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets)))\n",
        "mape_val = np.mean(np.abs((y_val_inv - y_val_pred_inv)/y_val_inv)) * 100\n",
        "r2_val = r2_score(y_val_inv.reshape(-1, num_targets), y_val_pred_inv.reshape(-1, num_targets))\n",
        "\n",
        "print(\"Validation Metrics after Random Search:\")\n",
        "print(f\"MAE: {mae_val:.2f}, RMSE: {rmse_val:.2f}, MAPE: {mape_val:.2f}%, R²: {r2_val:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UpV-vTOY3NO",
        "outputId": "25f4ef13-9bce-4e15-9540-4724bb2729f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation Metrics after Random Search:\n",
            "MAE: 80.55, RMSE: 131.74, MAPE: 6.66%, R²: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Hyperparameter Grid"
      ],
      "metadata": {
        "id": "pQlAzYEVY5dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grid for GRU\n",
        "units1_list = [32, 128]\n",
        "units2_list = [16, 64]\n",
        "dropout1_list = [0.1, 0.3]\n",
        "dropout2_list = [0.1, 0.3]\n",
        "learning_rate_list = [1e-3]\n"
      ],
      "metadata": {
        "id": "tkYQJJIlfuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search Loop for GRU"
      ],
      "metadata": {
        "id": "wQhZcb9Gf10p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "best_val_mae = float('inf')\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "for units1 in units1_list:\n",
        "    for units2 in units2_list:\n",
        "        for dropout1 in dropout1_list:\n",
        "            for dropout2 in dropout2_list:\n",
        "                for lr in learning_rate_list:\n",
        "\n",
        "                    # Build GRU model\n",
        "                    model = Sequential()\n",
        "                    model.add(GRU(\n",
        "                        units1,\n",
        "                        input_shape=(lookback, X_train.shape[2]),\n",
        "                        return_sequences=True\n",
        "                    ))\n",
        "                    model.add(Dropout(dropout1))\n",
        "\n",
        "                    model.add(GRU(\n",
        "                        units2,\n",
        "                        return_sequences=False\n",
        "                    ))\n",
        "                    model.add(Dropout(dropout2))\n",
        "\n",
        "                    model.add(Dense(horizon * num_targets))\n",
        "\n",
        "                    model.compile(\n",
        "                        optimizer=Adam(learning_rate=lr),\n",
        "                        loss='mse'\n",
        "                    )\n",
        "\n",
        "                    # Train on TRAIN set only\n",
        "                    model.fit(\n",
        "                        X_train,\n",
        "                        y_train.reshape(y_train.shape[0], horizon * num_targets),\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        verbose=0\n",
        "                    )\n",
        "\n",
        "                    # ----- Validation -----\n",
        "                    y_val_pred = model.predict(X_val)\n",
        "                    y_val_pred = y_val_pred.reshape(y_val.shape[0], horizon, num_targets)\n",
        "\n",
        "                    y_val_inv = target_scaler.inverse_transform(\n",
        "                        y_val.reshape(-1, num_targets)\n",
        "                    ).reshape(y_val.shape)\n",
        "\n",
        "                    y_val_pred_inv = target_scaler.inverse_transform(\n",
        "                        y_val_pred.reshape(-1, num_targets)\n",
        "                    ).reshape(y_val_pred.shape)\n",
        "\n",
        "                    val_mae = mean_absolute_error(\n",
        "                        y_val_inv.reshape(-1, num_targets),\n",
        "                        y_val_pred_inv.reshape(-1, num_targets)\n",
        "                    )\n",
        "\n",
        "                    print(\n",
        "                        f\"units1:{units1}, units2:{units2}, \"\n",
        "                        f\"d1:{dropout1}, d2:{dropout2}, \"\n",
        "                        f\"lr:{lr}, val_MAE:{val_mae:.2f}\"\n",
        "                    )\n",
        "\n",
        "                    # Save best model\n",
        "                    if val_mae < best_val_mae:\n",
        "                        best_val_mae = val_mae\n",
        "                        best_params = (units1, units2, dropout1, dropout2, lr)\n",
        "                        best_model = model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMIckXITgCuM",
        "outputId": "3662e4a4-2ac4-4891-acda-0e10e07ec134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "units1:32, units2:16, d1:0.1, d2:0.1, lr:0.001, val_MAE:88.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "units1:32, units2:16, d1:0.1, d2:0.3, lr:0.001, val_MAE:91.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step\n",
            "units1:32, units2:16, d1:0.3, d2:0.1, lr:0.001, val_MAE:84.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "units1:32, units2:16, d1:0.3, d2:0.3, lr:0.001, val_MAE:100.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "units1:32, units2:64, d1:0.1, d2:0.1, lr:0.001, val_MAE:80.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "units1:32, units2:64, d1:0.1, d2:0.3, lr:0.001, val_MAE:90.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n",
            "units1:32, units2:64, d1:0.3, d2:0.1, lr:0.001, val_MAE:99.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "units1:32, units2:64, d1:0.3, d2:0.3, lr:0.001, val_MAE:90.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "units1:128, units2:16, d1:0.1, d2:0.1, lr:0.001, val_MAE:79.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "units1:128, units2:16, d1:0.1, d2:0.3, lr:0.001, val_MAE:89.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "units1:128, units2:16, d1:0.3, d2:0.1, lr:0.001, val_MAE:85.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n",
            "units1:128, units2:16, d1:0.3, d2:0.3, lr:0.001, val_MAE:92.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
            "units1:128, units2:64, d1:0.1, d2:0.1, lr:0.001, val_MAE:81.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "units1:128, units2:64, d1:0.1, d2:0.3, lr:0.001, val_MAE:77.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "units1:128, units2:64, d1:0.3, d2:0.1, lr:0.001, val_MAE:94.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n",
            "units1:128, units2:64, d1:0.3, d2:0.3, lr:0.001, val_MAE:86.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print Best Hyperparameters"
      ],
      "metadata": {
        "id": "Yj7rZXIHgG3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters Found (GRU Grid Search):\")\n",
        "print(f\"units1: {best_params[0]}\")\n",
        "print(f\"units2: {best_params[1]}\")\n",
        "print(f\"dropout1: {best_params[2]}\")\n",
        "print(f\"dropout2: {best_params[3]}\")\n",
        "print(f\"learning_rate: {best_params[4]}\")\n",
        "print(f\"Best Validation MAE: {best_val_mae:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NoDFCovgKWw",
        "outputId": "b16247bf-8f69-4e78-87e3-e057f514f789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters Found (GRU Grid Search):\n",
            "units1: 128\n",
            "units2: 64\n",
            "dropout1: 0.1\n",
            "dropout2: 0.3\n",
            "learning_rate: 0.001\n",
            "Best Validation MAE: 77.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gq5Aa-6ygN4z"
      }
    }
  ]
}